{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0d6566d",
   "metadata": {},
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ba5aaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/cu102/torch_stable.html\n",
      "Requirement already satisfied: torch==1.10.1+cu102 in c:\\programdata\\anaconda3\\lib\\site-packages (1.10.1+cu102)\n",
      "Requirement already satisfied: torchvision==0.11.2+cu102 in c:\\programdata\\anaconda3\\lib\\site-packages (0.11.2+cu102)\n",
      "Requirement already satisfied: torchaudio===0.10.1+cu102 in c:\\programdata\\anaconda3\\lib\\site-packages (0.10.1+cu102)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==1.10.1+cu102) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision==0.11.2+cu102) (1.20.1)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision==0.11.2+cu102) (8.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.10.1+cu102 torchvision==0.11.2+cu102 torchaudio===0.10.1+cu102 -f https://download.pytorch.org/whl/cu102/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db31aad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\programdata\\anaconda3\\lib\\site-packages (0.1.96)\n"
     ]
    }
   ],
   "source": [
    "# Pegasus would not run without this\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ba79fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\programdata\\anaconda3\\lib\\site-packages (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (1.20.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: sacremoses in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.0.47)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6ec147",
   "metadata": {},
   "source": [
    "## What is Pytorch? \n",
    "It is an open source machine learning framework that accelerates the path from research prototyping to production deployment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4735ca",
   "metadata": {},
   "source": [
    "# Import and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba56e535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies from transformers\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdc8b05",
   "metadata": {},
   "source": [
    "## What is Pegasus?\n",
    "After some digging around I found that instead of using NLTK and other methods of sentence summary I could use Pytorch and Pegasus. Pegasus is a model taht was pre-trained on gap setnences from the body of text (corpus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "504e1903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98502aedb8c493386f38d34152adff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f70baaf8124aa199c492f172770dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f7a905a1be42c8a3600b095d4adbc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/87.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a373d76f5a1d49888b4cdf23a8164df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating Tokenizer\n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4cc4fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.pegasus.tokenization_pegasus.PegasusTokenizer"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b84c64f",
   "metadata": {},
   "source": [
    "A token is something used to take paragraphs or sentences, and turn them into number tokens to be rated indivudualy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bd88d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in pre-trained model \n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9324ccf",
   "metadata": {},
   "source": [
    "# Pegasus model\n",
    "As said before Pegasus is a pre-trained model. To get this model on our system we download it. This is a huge model which was 2.12gb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9417dc9d",
   "metadata": {},
   "source": [
    "# Performing Abstractive Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82506c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "The Lord of the Rings is an epic[1] high-fantasy novel[a] by English author and scholar J. R. R. Tolkien. Set in Middle-earth, intended to be Earth at some distant time in the past, the story began as a sequel to Tolkien's 1937 children's book The Hobbit, but eventually developed into a much larger work. Written in stages between 1937 and 1949, The Lord of the Rings is one of the best-selling books ever written, with over 150 million copies sold.[2]\n",
    "\n",
    "The title refers to the story's main antagonist, the Dark Lord Sauron, who in an earlier age created the One Ring to rule the other Rings of Power given to Men, Dwarves, and Elves, in his campaign to conquer all of Middle-earth. From homely beginnings in the Shire, a hobbit land reminiscent of the English countryside, the story ranges across Middle-earth, following the quest to destroy the One Ring mainly through the eyes of the hobbits Frodo, Sam, Merry and Pippin.\n",
    "\n",
    "Although often called a trilogy, the work was intended by Tolkien to be one volume of a two-volume set along with The Silmarillion.[3][T 2] For economic reasons, The Lord of the Rings was published over the course of a year from 29 July 1954 to 20 October 1955, in three volumes[3][4] titled The Fellowship of the Ring, The Two Towers, and The Return of the King. The work is divided internally into six books, two per volume, with several appendices of background material. Some later editions print the entire work in a single volume, following the author's original intent.\n",
    "\n",
    "Tolkien's work, after an initially mixed reception by the literary establishment, has been the subject of extensive analysis of its themes and origins. Influences on this earlier work, and on the story of The Lord of the Rings, include philology, mythology, Christianity, earlier fantasy works, and his own experiences in the First World War.\n",
    "\n",
    "The Lord of the Rings has since been reprinted many times and translated into at least 38 languages.[b] Its enduring popularity has led to numerous references in popular culture, the founding of many societies by fans of Tolkien's works,[5] and the publication of many books about Tolkien and his works. It has inspired numerous derivative works, including paintings, music, films, television, video games, and board games, helping create and shape the modern fantasy genre, within which it is considered one of the greatest books of all time.\n",
    "\n",
    "Award-winning adaptations of The Lord of the Rings have been made for radio, theatre, and film. It has been named Britain's best novel of all time in the BBC's The Big Read.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2664ccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting text into token representation - numbers \n",
    "tokens = tokenizer(text, truncation=True, padding=\"longest\", return_tensors=\"pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44c851c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  139,  2346,   113,   109, 17557,   117,   142,  7277, 65077,  1100,\n",
       "           281,   121, 72074,  2794,  4101,   304,  1100,   141,  1188,  1782,\n",
       "           111, 15461,   907,   107,   840,   107,   840,   107, 40900,   107,\n",
       "          3089,   115,  3396,   121, 21019,   108,  2685,   112,   129,  2774,\n",
       "           134,   181,  9234,   166,   115,   109,   555,   108,   109,   584,\n",
       "          1219,   130,   114, 12677,   112, 40900,   131,   116, 21120,   404,\n",
       "           131,   116,   410,   139, 38844,   108,   155,  2435,  1184,   190,\n",
       "           114,   249,  1599,   201,   107, 16550,   115,  4208,   317, 21120,\n",
       "           111, 20322,   108,   139,  2346,   113,   109, 17557,   117,   156,\n",
       "           113,   109,   229,   121, 10346,  1031,   521,  1158,   108,   122,\n",
       "           204,  3968,   604,  4862,  1575,   107,  4101, 50558,   139,  1560,\n",
       "          6335,   112,   109,   584,   131,   116,   674, 45629,   108,   109,\n",
       "          5715,  2346, 29609,  7465,   108,   170,   115,   142,  1678,   779,\n",
       "           732,   109,   614,  8218,   112,  2613,   109,   176, 17557,   113,\n",
       "          2289,   634,   112,  3770,   108,   714,  7294,   261,   116,   108,\n",
       "           111, 66678,   108,   115,   169,  1541,   112, 18567,   149,   113,\n",
       "          3396,   121, 21019,   107,  1078, 45667, 19553,   115,   109, 28817,\n",
       "           108,   114, 48018,  1241, 14456,   113,   109,  1188,  8859,   108,\n",
       "           109,   584,  7682,   482,  3396,   121, 21019,   108,   645,   109,\n",
       "          7027,   112,  7208,   109,   614,  8218,  3187,   224,   109,  1525,\n",
       "           113,   109, 48018,   116, 69725,   108,  4037,   108, 16048,   111,\n",
       "         87657,   107,  2113,   432,   568,   114, 20331,   108,   109,   201,\n",
       "           140,  2685,   141, 40900,   112,   129,   156,  2410,   113,   114,\n",
       "           228,   121, 22439,   323,   466,   122,   139, 19127,  6520, 31338,\n",
       "           107,  4101,   726, 32887,   930,   280,  1100,   321,  1500,  1523,\n",
       "           108,   139,  2346,   113,   109, 17557,   140,  1299,   204,   109,\n",
       "           422,   113,   114,   232,   135,  3211,  1307, 22919,   112,   599,\n",
       "          1350, 18064,   108,   115,   339,  7912,  4101,   726, 32887, 60708,\n",
       "          6486,   139, 11919,   113,   109,  8218,   108,   139,  2508, 24050,\n",
       "           108,   111,   139,  9719,   113,   109,  2048,   107,   139,   201,\n",
       "           117,  5215, 12277,   190,  1029,  1031,   108,   228,   446,  2410,\n",
       "           108,   122,   500, 72133,   113,  1688,  1001,   107,  1027,   678,\n",
       "         14212,  1591,   109,   954,   201,   115,   114,   612,  2410,   108,\n",
       "           645,   109,  1782,   131,   116,   856,  6596,   107, 40900,   131,\n",
       "           116,   201,   108,   244,   142,  4471,  3044,  4595,   141,   109,\n",
       "          7898,  6354,   108,   148,   174,   109,  1220,   113,  2248,  1382,\n",
       "           113,   203,  4436,   111, 10959,   107, 27651,   116,   124,   136,\n",
       "          1678,   201,   108,   111,   124,   109,   584,   113,   139,  2346,\n",
       "           113,   109, 17557,   108,   444,   110, 23161,  6671,   108, 20947,\n",
       "           108, 11681,   108,  1678,  6528,   659,   108,   111,   169,   282,\n",
       "          1747,   115,   109,  1485,   894,  1981,   107,   139,  2346,   113,\n",
       "           109, 17557,   148,   381,   174, 49249,   223,   488,   111,  8839,\n",
       "           190,   134,   583,  5663,  4482,   107,  4101,  1271,  1100,  3096,\n",
       "         14669,  5312,   148,  1358,   112,  1866,  5607,   115,   785,  1378,\n",
       "           108,   109,  7862,   113,   223, 11773,   141,  1730,   113, 40900,\n",
       "           131,   116,   659,   108,  4101,  1343,  1100,   111,   109,  4157,\n",
       "           113,   223,  1031,   160, 40900,   111,   169,   659,   107,   168,\n",
       "           148,  2261,  1866, 22869,   659,   108,   330,  5205,   108,   534,\n",
       "           108,  3265,   108,  3069,   108,   545,   727,   108,   111,  1042,\n",
       "           727,   108,  1360,   421,   111,  1674,   109,   946,  6528,  6744,\n",
       "           108,   373,   162,   126,   117,  1341,   156,   113,   109,  2502,\n",
       "          1031,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying our tokens\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d2740e",
   "metadata": {},
   "source": [
    "### What we are doing is unpacking our input ID's and our attention maks\n",
    "This shows where our attention is going when we are applying our summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09ef2b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizing the text we input\n",
    "## The double ** is how we unpack\n",
    "summary = model.generate(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92abfb0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,   139,  2346,   113,   109, 17557,   117,   156,   113,   109,\n",
       "           229,   121, 10346,  1031,   521,  1158,   108,   122,   204,  3968,\n",
       "           604,  4862,  1575,   107,     1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary in tokens\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832766a0",
   "metadata": {},
   "source": [
    "We did it! But we dont know what these words mean until we decode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bc93420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Lord of the Rings is one of the best-selling books ever written, with over 150 million copies sold.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode summary\n",
    "# the summary is nested so we are grabbing our tokens from the summary\n",
    "tokenizer.decode(summary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1385d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
